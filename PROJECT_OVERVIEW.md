# Supabase SQL Schema Analysis Agent - Project Overview

## ğŸ“‹ Executive Summary

Sistema automatizado de revisiÃ³n de esquemas SQL para aplicaciones SaaS multi-tenant en Supabase. Analiza archivos SQL modificados en Pull Requests usando 3 modelos de IA diferentes (Claude Sonnet 4.5, GPT-5, Gemini 2.5 Pro) ejecutÃ¡ndose en paralelo para proporcionar anÃ¡lisis comparativos y exhaustivos.

**PropÃ³sito:** Detectar vulnerabilidades de seguridad, problemas de performance, violaciones de mejores prÃ¡cticas y fallas en aislamiento multi-tenant antes de que el cÃ³digo llegue a producciÃ³n.

---

## ğŸ—ï¸ Arquitectura del Sistema

### Stack TecnolÃ³gico

```
Language: TypeScript 5.7.2
Runtime: Node.js 20
Package Manager: npm
APIs:
  - Anthropic Claude API (@anthropic-ai/sdk ^0.32.1)
  - OpenAI API (openai)
  - Google Generative AI (@google/generative-ai)
  - GitHub REST API (@octokit/rest ^21.0.2)
Deployment: GitHub Actions (ubuntu-latest)
```

### Estructura de Directorios

```
agentes/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ sql-review.yml          # GitHub Actions workflow
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ analyzer.ts             # Claude Sonnet 4.5 analyzer
â”‚   â”‚   â”œâ”€â”€ openai-analyzer.ts      # GPT-5 analyzer
â”‚   â”‚   â”œâ”€â”€ gemini-analyzer.ts      # Gemini 2.5 Pro analyzer
â”‚   â”‚   â””â”€â”€ prompt.ts               # Shared analysis prompt (v6.0)
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â””â”€â”€ sql-reader.ts           # Lee archivos SQL del filesystem
â”‚   â”œâ”€â”€ github/
â”‚   â”‚   â”œâ”€â”€ pr-handler.ts           # InteractÃºa con GitHub API para PRs
â”‚   â”‚   â”œâ”€â”€ commenter.ts            # Posta comentarios en PRs
â”‚   â”‚   â””â”€â”€ reporter.ts             # Genera reportes detallados
â”‚   â””â”€â”€ index.ts                    # Punto de entrada principal
â”œâ”€â”€ sql/                            # Directorio monitoreado (archivos SQL)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .env.example
â””â”€â”€ PROJECT_OVERVIEW.md             # Este archivo
```

---

## ğŸ”„ Flujo de Trabajo Completo

### 1. Trigger (GitHub Actions)

**Evento disparador:**
```yaml
on:
  pull_request:
    paths:
      - 'sql/**/*.sql'
```

**Condiciones:**
- Solo se ejecuta en Pull Requests (no en push directo a main)
- Solo si hay cambios en archivos dentro de `sql/` con extensiÃ³n `.sql`

### 2. InicializaciÃ³n

**Variables de entorno requeridas:**
```
GITHUB_TOKEN          # Auto-provisto por GitHub Actions
ANTHROPIC_API_KEY     # Secret: API key de Anthropic
OPENAI_API_KEY        # Secret: API key de OpenAI
GEMINI_API_KEY        # Secret: API key de Google AI
GITHUB_REPOSITORY     # Auto: owner/repo
PR_NUMBER             # Auto: nÃºmero del PR
```

**Componentes instanciados:**
```typescript
PRHandler(githubToken, owner, repo)           // Maneja operaciones con GitHub API
SQLReader('sql')                              // Lee archivos del directorio sql/
SQLAnalyzer(anthropicApiKey)                  // Analizador Claude
OpenAIAnalyzer(openaiApiKey)                  // Analizador GPT-5
GeminiAnalyzer(geminiApiKey)                  // Analizador Gemini
PRCommenter(githubToken, owner, repo)         // Posta comentarios
```

### 3. DetecciÃ³n de Archivos Modificados

**Proceso:**
1. `PRHandler.getPRInfo(prNumber)` â†’ obtiene metadata del PR
2. `PRHandler.getChangedSQLFiles(prNumber)` â†’ lista archivos modificados
3. Filtra solo archivos en `sql/` directory
4. Excluye archivos con status `removed`

**Resultado:** Array de `{filename, status}` donde status = `added|modified|renamed`

### 4. Lectura de Contenido SQL

**Proceso:**
1. `SQLReader.readMultipleSQLFiles(filenames)`
2. Lee contenido de cada archivo usando `fs.promises.readFile`
3. Detecta encoding (UTF-8)

**Resultado:** Array de `{filename, content}`

### 5. AnÃ¡lisis Multi-Modelo (Paralelo)

**EjecuciÃ³n:**
```typescript
const [anthropicResults, openaiResults, geminiResults] = await Promise.all([
  anthropicAnalyzer.analyzeMultipleFiles(files),
  openaiAnalyzer.analyzeMultipleFiles(files),
  geminiAnalyzer.analyzeMultipleFiles(files)
]);
```

**Dentro de cada analyzer:**
1. Itera secuencialmente sobre cada archivo (para mantener rate limits)
2. Construye prompt usando `getAnalysisPrompt(sqlContent, filename)`
3. Llama a API del modelo correspondiente
4. Extrae JSON de respuesta (maneja code blocks)
5. Parsea a `AnalysisResult`
6. Maneja errores y retorna resultado default si falla

**ConfiguraciÃ³n de modelos:**
```typescript
// Claude Sonnet 4.5
model: 'claude-sonnet-4-5-20250929'
max_tokens: 4096
temperature: 1.0 (default, no especificado)

// GPT-5
model: 'gpt-5'
max_tokens: 4096
temperature: 1.0

// Gemini 2.5 Pro
model: 'gemini-2.5-pro'
maxOutputTokens: 4096
temperature: 1.0
```

### 6. GeneraciÃ³n de Comentarios

**Proceso:**
1. Para cada modelo (3 comentarios separados):
   - Formatea resultado usando `commenter.formatAnalysisComment()`
   - Incluye metadata: AI model name + version
   - Calcula mÃ©tricas agregadas (score promedio, total de issues)
   - Genera executive summary
   - Lista issues por archivo
   - Incluye good practices encontradas
   - Genera action plan
2. Posta comentario vÃ­a GitHub API: `octokit.issues.createComment()`

**Orden de posteo:**
1. Claude Sonnet 4.5
2. GPT-5
3. Gemini 2.5 Pro

### 7. Reporte Job Summary

**Proceso:**
1. `GitHubReporter.generateJobSummary(results)` â†’ genera markdown detallado
2. `GitHubReporter.writeJobSummary()` â†’ escribe a `GITHUB_STEP_SUMMARY`
3. Visible en la pestaÃ±a "Summary" de GitHub Actions run

---

## ğŸ¤– Sistema de AnÃ¡lisis de IA

### Prompt Engineering (v6.0)

**UbicaciÃ³n:** `src/agent/prompt.ts` â†’ `getAnalysisPrompt()`

**CaracterÃ­sticas del prompt:**

#### Contexto del Proyecto
```
- Sistema SaaS multi-tenant (tenant_id en mayorÃ­a de tablas)
- RLS, Ã­ndices y triggers en /supabase/migrations/
- Secrets globales (Resend, Tremendous, Stripe) en Supabase Vault
- Edge Functions acceden secrets vÃ­a Deno.env.get()
```

#### Convenciones de Seguridad
```
âœ… Outbound keys (servidor â†’ API externa): texto plano OK
ğŸš¨ Inbound keys (cliente â†’ servidor): hasheadas obligatorio
ğŸš¨ Refresh tokens: hasheados obligatorio
âš ï¸ SSO tokens: OK si TTL < 60s + cleanup automÃ¡tico
```

#### 5 Ãreas de EvaluaciÃ³n

1. **Seguridad Multi-Tenant**
   - ENABLE ROW LEVEL SECURITY visible
   - Aislamiento entre tenants verificable
   - Riesgo de data leakage

2. **Integridad de Datos**
   - Foreign Keys correctas con ON DELETE apropiado
   - UNIQUE y CHECK constraints correctos
   - Campos crÃ­ticos con NOT NULL

3. **Seguridad de Credenciales**
   - Inbound keys/tokens sin hash â†’ CRITICAL
   - Outbound keys visibles â†’ OK
   - Secrets sensibles fuera de Vault

4. **Performance y Escalabilidad**
   - Ãndices en tenant_id, user_id o FK ausentes
   - Escalabilidad para >10k registros/tenant

5. **Mejores PrÃ¡cticas y Convenciones**
   - UUIDs como PKs
   - Campos created_at y updated_at
   - Naming snake_case
   - Uso de JSONB en lugar de JSON

#### ClasificaciÃ³n de Severidad

**CRITICAL** (problema visible en archivo):
- Inbound key/token sin hash
- ContraseÃ±a en texto plano
- FK rota o mal definida
- NULL en campo crÃ­tico (tenant_id, user_id)
- ViolaciÃ³n del aislamiento multi-tenant

**WARNING** (ausencia verificable, puede estar en migraciones):
- RLS no visible
- Ãndices faltantes
- TTL o constraint ausente

**SUGGESTION** (mejora opcional):
- Naming
- Cascade policies
- Index tuning

#### Formato de Respuesta JSON

```json
{
  "score": 8.7,
  "summary": "Breve resumen del archivo (snapshot/migraciÃ³n)",
  "critical": [
    {
      "table": "user_api_keys",
      "issue": "Inbound API key sin hash",
      "location": "CREATE TABLE user_api_keys (key TEXT ...)",
      "risk": "ExposiciÃ³n total de credenciales",
      "fix": "ALTER TABLE ... ADD COLUMN key_hash TEXT;",
      "present_in_file": true,
      "confidence": 100,
      "verification_needed": null
    }
  ],
  "warnings": [
    {
      "table": "orders",
      "issue": "RLS no visible",
      "impact": "Aislamiento multi-tenant podrÃ­a romperse",
      "fix": "Verificar en /supabase/migrations/",
      "present_in_file": false,
      "confidence": 90,
      "verification_needed": "/supabase/migrations/*.sql"
    }
  ],
  "suggestions": [...],
  "goodPractices": [
    "Uso de UUIDs como PK",
    "Campos created_at y updated_at presentes"
  ],
  "actionPlan": [
    "1. [CRÃTICO] Hashear inbound keys - inmediato",
    "2. [VERIFICAR] Confirmar RLS en migrations - 5 min"
  ]
}
```

#### Pre-Check Obligatorio

Antes de generar JSON, el modelo debe verificar:
- âœ… IdentificÃ³ tipo de archivo (snapshot, migraciÃ³n, dump)
- âœ… DiferenciÃ³ "no presente aquÃ­" vs "no existe en sistema"
- âœ… IncluyÃ³ present_in_file, confidence, verification_needed
- âœ… No marcÃ³ CRITICAL por algo que podrÃ­a estar en migraciones
- âœ… CitÃ³ bloque SQL exacto en location
- âœ… IdentificÃ³ al menos 3 buenas prÃ¡cticas (o [] si no hay)
- âœ… Score refleja solo problemas visibles

#### Reglas Anti-Falsos Positivos

- âŒ No marcar CRITICAL por RLS/Ã­ndices ausentes (pueden estar en migraciones)
- âŒ No inventar hechos tÃ©cnicos sin evidencia textual
- âŒ No citar "prÃ¡ctica estÃ¡ndar" sin URL oficial
- âŒ No declarar falsos positivos sin ver SQL
- âœ… Usar WARNING + verificaciÃ³n para dudas legÃ­timas

#### Notas TÃ©cnicas

```
JSONB vs JSON â†’ usa JSONB (indexable, eficiente)
auth.uid() â†’ debe usarse en RLS (no current_user)
Vault secrets â†’ nunca en SQL, se acceden desde Edge Functions
```

---

## ğŸ“Š Formato de Comentarios en PR

### Estructura de Cada Comentario

```markdown
## ğŸ” Supabase SQL Schema Analysis

**ğŸ¤– AI Model:** Claude Sonnet 4.5 / GPT-5 / Gemini 2.5 Pro
**ğŸ“Œ Version:** `claude-sonnet-4-5-20250929` / `gpt-5` / `gemini-2.5-pro`

### ğŸ“Š Executive Summary

| Metric | Value |
|--------|-------|
| Files Analyzed | 2 |
| Overall Score | **8.5/10** |
| ğŸš¨ Critical Issues | 1 |
| âš ï¸ Warnings | 3 |
| â„¹ï¸ Suggestions | 2 |
| â±ï¸ Est. Fix Time | ~20 min |

> **ğŸš¨ ACTION REQUIRED** - 1 critical issue(s) must be resolved before merging

[ğŸ“‹ View detailed report in GitHub Actions](https://github.com/...)

---

### ğŸ“„ `schema.sql` - Score: **8.5/10**

**Summary:** Schema snapshot con estructura multi-tenant correcta.

#### ğŸš¨ Critical Issues (1)

**1.** Tabla 'user_api_keys' sin hash
- **Risk:** ExposiciÃ³n de credenciales si la base es comprometida
- **Fix:**
```sql
ALTER TABLE user_api_keys ADD COLUMN key_hash TEXT;
-- aplicar bcrypt/argon2 en capa de aplicaciÃ³n
```

#### âš ï¸ Warnings (3)

**1.** RLS no visible en este snapshot
- **Impact:** Si no estÃ¡ en migraciones: aislamiento multi-tenant podrÃ­a romperse
- **Fix:**
```sql
-- Verificar en /supabase/migrations/:
ALTER TABLE orders ENABLE ROW LEVEL SECURITY;
```

#### â„¹ï¸ Suggestions (2)

**1.** Considerar agregar ON DELETE CASCADE
- **Benefit:** Limpieza automÃ¡tica de datos huÃ©rfanos
- **Implementation:**
```sql
ALTER TABLE orders DROP CONSTRAINT orders_user_id_fkey;
ALTER TABLE orders ADD CONSTRAINT orders_user_id_fkey
  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;
```

#### âœ… Good Practices Found

- Uso de UUIDs como PK
- Campos created_at y updated_at presentes
- FKs con nombres descriptivos
- NOT NULL en campos crÃ­ticos

#### ğŸ“‹ Action Plan

1. [CRÃTICO] Hashear inbound API keys - inmediato
2. [VERIFICAR] Confirmar RLS en /supabase/migrations/ - 5 min
3. [IMPORTANTE] Agregar Ã­ndices en tenant_id y FKs - 10 min

---

*Analysis powered by Claude Sonnet 4.5 (claude-sonnet-4-5-20250929) | Generated by [Supabase SQL Agent](https://github.com/...)*
```

---

## ğŸ”§ ConfiguraciÃ³n y Setup

### Variables de Entorno (.env)

```bash
# GitHub Configuration
GITHUB_TOKEN=ghp_your_github_token_here
GITHUB_REPOSITORY=owner/repo

# AI Model API Keys
ANTHROPIC_API_KEY=sk-ant-your_api_key_here
OPENAI_API_KEY=sk-your_openai_key_here
GEMINI_API_KEY=your_gemini_key_here

# Pull Request Number (automatically set by GitHub Actions)
PR_NUMBER=1
```

### GitHub Secrets Requeridos

```
Repository â†’ Settings â†’ Secrets and variables â†’ Actions â†’ New repository secret

ANTHROPIC_API_KEY â†’ API key de Anthropic Claude
OPENAI_API_KEY    â†’ API key de OpenAI
GEMINI_API_KEY    â†’ API key de Google AI Studio
```

### InstalaciÃ³n Local

```bash
# 1. Clonar repositorio
git clone https://github.com/owner/repo.git
cd agentes

# 2. Instalar dependencias
npm install

# 3. Compilar TypeScript
npm run build

# 4. Configurar .env (copiar de .env.example)
cp .env.example .env
# Editar .env con tus API keys

# 5. Ejecutar localmente
npm start
```

### Scripts npm

```json
{
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js",
    "dev": "tsx src/index.ts"
  }
}
```

---

## ğŸ¯ Casos de Uso y Escenarios

### Escenario 1: Nueva Tabla Multi-Tenant

**Archivo:** `sql/create_tenants_table.sql`
```sql
CREATE TABLE tenants (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT now()
);
```

**AnÃ¡lisis esperado:**
- âš ï¸ WARNING: RLS no visible en snapshot
- âš ï¸ WARNING: Falta Ã­ndice en campos de bÃºsqueda frecuente
- âœ… GOOD: UUIDs como PK
- âœ… GOOD: created_at con DEFAULT
- Score: ~7.5-8.0/10

### Escenario 2: API Keys sin Hash (CRÃTICO)

**Archivo:** `sql/add_api_keys.sql`
```sql
CREATE TABLE user_api_keys (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id),
  api_key TEXT NOT NULL,  -- âŒ INBOUND KEY SIN HASH
  created_at TIMESTAMPTZ DEFAULT now()
);
```

**AnÃ¡lisis esperado:**
- ğŸš¨ CRITICAL: Inbound API key sin hash
- âš ï¸ WARNING: RLS no visible
- âš ï¸ WARNING: Falta ON DELETE en FK
- Score: â‰¤6.0/10 (por issue crÃ­tico)

### Escenario 3: Schema Perfecto

**Archivo:** `sql/orders_table.sql`
```sql
CREATE TABLE orders (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  status TEXT NOT NULL CHECK (status IN ('pending', 'completed', 'cancelled')),
  metadata JSONB DEFAULT '{}'::jsonb,
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_orders_tenant_id ON orders(tenant_id);
CREATE INDEX idx_orders_user_id ON orders(user_id);

ALTER TABLE orders ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can only see their tenant orders" ON orders
  FOR SELECT USING (tenant_id = (SELECT tenant_id FROM users WHERE id = auth.uid()));
```

**AnÃ¡lisis esperado:**
- âœ… GOOD: UUIDs, timestamps, NOT NULL, CHECK constraint
- âœ… GOOD: JSONB (no JSON)
- âœ… GOOD: Ãndices en FKs y tenant_id
- âœ… GOOD: ON DELETE CASCADE
- âœ… GOOD: RLS habilitado con polÃ­tica correcta
- Score: 9.5-10.0/10

---

## ğŸ“ˆ MÃ©tricas y KPIs

### MÃ©tricas Calculadas

```typescript
// Por anÃ¡lisis
avgScore = sum(scores) / totalFiles
totalCritical = sum(critical.length)
totalWarnings = sum(warnings.length)
totalSuggestions = sum(suggestions.length)
estimatedTime = critical * 5 + warnings * 3 + suggestions * 2 (minutos)

// Status badge logic
if (totalCritical > 0) â†’ "ğŸš¨ ACTION REQUIRED"
else if (totalWarnings > 0) â†’ "âœ… READY"
else â†’ "ğŸ‰ EXCELLENT"
```

### Criterios de Score

```
10.0 â†’ Schema perfecto, cero issues
9.0-9.9 â†’ Excelente, solo sugerencias menores
8.0-8.9 â†’ Bueno, algunos warnings no crÃ­ticos
7.0-7.9 â†’ Aceptable, warnings importantes
6.0-6.9 â†’ Revisar, mÃºltiples warnings o 1 critical
<6.0 â†’ Bloquear, mÃºltiples critical issues
```

---

## ğŸ” Ãreas de Mejora Identificadas

### 1. Performance y Escalabilidad

**Problema actual:**
- AnÃ¡lisis secuencial dentro de cada modelo (para evitar rate limits)
- 3 modelos en paralelo, pero cada uno procesa archivos uno por uno

**Mejora propuesta:**
- Implementar batching inteligente
- Rate limiting configurable por modelo
- Cache de resultados para archivos no modificados

### 2. DetecciÃ³n de Cambios

**Problema actual:**
- Analiza archivo completo aunque solo cambiÃ³ 1 lÃ­nea

**Mejora propuesta:**
- Diff analysis: analizar solo lÃ­neas modificadas
- Context-aware: mantener contexto de tablas relacionadas
- Incremental analysis: comparar con versiÃ³n anterior

### 3. Consenso Multi-Modelo

**Problema actual:**
- 3 comentarios separados, sin sÃ­ntesis

**Mejora propuesta:**
- Comentario adicional con consenso:
  - Issues detectados por 2+ modelos (alta confianza)
  - Issues detectados por 1 modelo (requiere validaciÃ³n)
  - Discrepancias significativas en scores
  - RecomendaciÃ³n final consolidada

### 4. False Positives

**Problema actual:**
- Puede marcar warnings por RLS ausente aunque estÃ© en migraciones

**Mejora propuesta:**
- Escaneo de `/supabase/migrations/` para verificar RLS, Ã­ndices, triggers
- Cross-reference entre snapshot y migraciones
- Confianza ajustada basada en verificaciÃ³n cruzada

### 5. Testing y ValidaciÃ³n

**Problema actual:**
- No hay tests automatizados

**Mejora propuesta:**
- Unit tests para cada analyzer
- Integration tests con mocks de APIs
- Fixture SQLs con casos conocidos
- Regression tests para evitar falsos positivos

### 6. Cost Optimization

**Problema actual:**
- 3 llamadas API completas por archivo (costo $$$)

**Mejora propuesta:**
- Modo "fast" con solo 1 modelo para PRs pequeÃ±os
- Modo "thorough" con 3 modelos para PRs crÃ­ticos
- Caching de resultados para re-anÃ¡lisis
- Sampling inteligente (analizar subset de archivos)

### 7. Observabilidad

**Problema actual:**
- Logging limitado, difÃ­cil debuggear fallos

**Mejora propuesta:**
- Structured logging (JSON)
- MÃ©tricas de latencia por modelo
- Error tracking (Sentry/similar)
- Dashboard de anÃ¡lisis histÃ³ricos

### 8. Configurabilidad

**Problema actual:**
- Prompt hardcoded, no customizable por proyecto

**Mejora propuesta:**
- `sql-analysis.config.json` en root:
  ```json
  {
    "models": ["claude", "gpt5"],
    "strictness": "high",
    "customRules": [...],
    "ignorePatterns": ["migrations/seed_*.sql"]
  }
  ```

### 9. Soporte para Otros Databases

**Problema actual:**
- Solo Supabase/PostgreSQL

**Mejora propuesta:**
- DetecciÃ³n automÃ¡tica de DB engine
- Prompts especÃ­ficos por engine (MySQL, MongoDB, etc.)
- Plugins extensibles para nuevos engines

### 10. Auto-Fix Capabilities

**Problema actual:**
- Solo sugiere fixes, no los aplica

**Mejora propuesta:**
- Modo "auto-fix" para issues no-crÃ­ticos
- PR automÃ¡tico con fixes propuestos
- AprobaciÃ³n humana antes de merge

---

## ğŸš€ Roadmap Sugerido

### Phase 1: Stability & Testing (1-2 semanas)
- [ ] Agregar unit tests (coverage >80%)
- [ ] Integration tests con mocks
- [ ] Error handling robusto
- [ ] Structured logging

### Phase 2: Intelligence (2-3 semanas)
- [ ] Consenso multi-modelo
- [ ] Cross-reference con migrations
- [ ] Diff-based analysis
- [ ] False positive reduction

### Phase 3: Performance (1-2 semanas)
- [ ] Caching de resultados
- [ ] Rate limiting inteligente
- [ ] Batch processing optimizado
- [ ] Cost tracking

### Phase 4: Extensibility (2-3 semanas)
- [ ] Config file support
- [ ] Plugin system
- [ ] Custom rules engine
- [ ] Multi-database support

### Phase 5: Automation (1-2 semanas)
- [ ] Auto-fix para issues simples
- [ ] PR automÃ¡tico con fixes
- [ ] Dashboard de mÃ©tricas
- [ ] Historical analysis

---

## ğŸ“š Referencias y DocumentaciÃ³n

### APIs Utilizadas

- **Anthropic Claude:** https://docs.anthropic.com/claude/reference/
- **OpenAI:** https://platform.openai.com/docs/api-reference
- **Google Gemini:** https://ai.google.dev/gemini-api/docs
- **GitHub REST API:** https://docs.github.com/rest
- **Octokit:** https://octokit.github.io/rest.js/

### Best Practices

- **Supabase RLS:** https://supabase.com/docs/guides/auth/row-level-security
- **PostgreSQL Security:** https://www.postgresql.org/docs/current/ddl-rowsecurity.html
- **Multi-tenant Architecture:** https://docs.aws.amazon.com/wellarchitected/latest/saas-lens/
- **SQL Injection Prevention:** https://owasp.org/www-community/attacks/SQL_Injection

### Herramientas Relacionadas

- **sqlfluff:** SQL linter (reglas estÃ¡ticas)
- **pganalyze:** Performance monitoring para Postgres
- **Liquibase:** Database schema versioning
- **Flyway:** Database migrations

---

## ğŸ“ ConclusiÃ³n

Este proyecto representa una soluciÃ³n robusta para automatizar la revisiÃ³n de seguridad y calidad de esquemas SQL en entornos multi-tenant. La arquitectura multi-modelo proporciona redundancia y diversidad de perspectivas, reduciendo significativamente el riesgo de falsos negativos.

**Fortalezas principales:**
1. âœ… AnÃ¡lisis exhaustivo en 5 Ã¡reas crÃ­ticas
2. âœ… Multi-modelo para alta confianza
3. âœ… Prompt v6.0 con anti-falsos positivos
4. âœ… IntegraciÃ³n nativa con GitHub Actions
5. âœ… Comentarios detallados y accionables

**Limitaciones actuales:**
1. âš ï¸ Alto costo por anÃ¡lisis (3 modelos x archivo)
2. âš ï¸ No considera migraciones existentes
3. âš ï¸ Sin tests automatizados
4. âš ï¸ Falta consenso entre modelos
5. âš ï¸ No soporta auto-fixes

**Next Steps:**
- Implementar testing suite completo
- Agregar consenso multi-modelo
- Cross-reference con migrations directory
- Cost optimization mediante sampling inteligente

---

**VersiÃ³n del documento:** 1.0
**Ãšltima actualizaciÃ³n:** 2025-10-30
**Autor:** Sistema automatizado
**Modelos activos:** Claude Sonnet 4.5, GPT-5, Gemini 2.5 Pro
